{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Gold Futures Forecasting with Chronos Models: 2016-2019 Analysis\n\n## Comprehensive Performance Evaluation in Stable Market Conditions\n\n### Objectives\n1. Evaluate Chronos model performance on gold futures forecasting during 2016-2019 period\n2. Use rolling window approach with optimized context lengths for next-day predictions\n3. Analyze performance in stable, pre-COVID market conditions (2016-2019)\n4. Compare against baseline models using standardized metrics (MASE, MAE, RMSE, directional accuracy)\n5. Perform systematic configuration optimization for stable market conditions\n6. Provide comparison baseline for volatile market period analysis (2020-2021)\n\n### Methodology\n- **Data**: GCUSD (Gold Futures) daily OHLCV data from 2016-2019 (4-year stable period)\n- **Models**: Chronos-Bolt family with systematic configuration optimization\n- **Evaluation**: Rolling window approach with configurable context lengths (30, 63, 126, 252 days)\n- **Benchmarking**: Comprehensive metrics including MASE, MAE, RMSE, MAPE, and directional accuracy\n- **Optimization**: Systematic testing of model sizes, context windows, and prediction horizons\n- **Market Context**: Analysis of stable, lower-volatility market conditions\n\n### Key Hypothesis\nThe 2016-2019 period represents stable market conditions with:\n- **Lower volatility** compared to COVID-era markets (2020-2021)\n- **Gradual price movements** with fewer extreme events\n- **Consistent market dynamics** favoring pattern recognition\n- **Optimal conditions** for sophisticated forecasting models\n\nThis analysis will test whether Chronos models perform better relative to naive baselines in stable market conditions, providing a crucial comparison point for understanding market regime effects on forecasting performance.",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages\nprint(\"Installing required packages for 2016-2019 analysis...\")\nimport subprocess\nimport sys\nimport os\n\ndef install_package(package_name, alternative_name=None):\n    \"\"\"Install a package with fallback options\"\"\"\n    try:\n        # Try pip install first\n        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package_name, \"--quiet\"], \n                      check=True, capture_output=True)\n        print(f\"✅ {package_name} installed via pip\")\n        return True\n    except subprocess.CalledProcessError:\n        # If pip fails, try with --break-system-packages (not recommended but sometimes necessary)\n        try:\n            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package_name, \"--break-system-packages\", \"--quiet\"], \n                          check=True, capture_output=True)\n            print(f\"✅ {package_name} installed via pip (system packages)\")\n            return True\n        except subprocess.CalledProcessError:\n            print(f\"❌ Failed to install {package_name}\")\n            return False\n\n# Install packages in order of importance\npackages = [\n    (\"pandas\", \"python3-pandas\"),\n    (\"numpy\", \"python3-numpy\"),\n    (\"matplotlib\", \"python3-matplotlib\"),\n    (\"seaborn\", \"python3-seaborn\"),\n    (\"scipy\", \"python3-scipy\"),\n    (\"scikit-learn\", \"python3-sklearn\"),\n    (\"torch\", None),  # PyTorch for Chronos\n    (\"chronos-forecasting\", None),\n    (\"fev\", None),  # FEV - Forecast Evaluation Framework\n    (\"datasets\", None),  # Hugging Face datasets (required for FEV)\n    (\"plotly\", \"python3-plotly\"),\n    (\"bokeh\", \"python3-bokeh\"),\n    (\"ipywidgets\", \"python3-ipywidgets\")\n]\n\nprint(\"Installing core packages...\")\nfor package, alt_name in packages:\n    install_package(package, alt_name)\n\nprint(\"\\n2016-2019 analysis environment setup completed!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for 2016-2019 analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core plotting libraries\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    print(\"✅ Matplotlib and seaborn imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error importing matplotlib/seaborn: {e}\")\n",
    "    # Handle installation if needed\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'matplotlib', 'seaborn', '--break-system-packages', '--quiet'])\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    print(\"✅ Matplotlib and seaborn installed and imported\")\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Chronos imports\n",
    "try:\n",
    "    import torch\n",
    "    from chronos import BaseChronosPipeline\n",
    "    print(\"✅ Chronos imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error importing Chronos: {e}\")\n",
    "    print(\"Installing chronos-forecasting...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'chronos-forecasting', '--break-system-packages', '--quiet'])\n",
    "    import torch\n",
    "    from chronos import BaseChronosPipeline\n",
    "    print(\"✅ Chronos installed and imported\")\n",
    "\n",
    "# FEV imports (Forecast Evaluation Framework)\n",
    "fev_available = False\n",
    "try:\n",
    "    import fev\n",
    "    from datasets import Dataset\n",
    "    fev_available = True\n",
    "    print(\"✅ FEV imports successful\")\n",
    "    print(f\"FEV version: {fev.__version__ if hasattr(fev, '__version__') else 'Version info not available'}\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ FEV not available: {e}\")\n",
    "    print(\"Will use alternative evaluation framework\")\n",
    "\n",
    "# Interactive visualization imports\n",
    "plotly_available = False\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.express as px\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.io as pio\n",
    "    pio.renderers.default = \"plotly_mimetype+notebook\"\n",
    "    plotly_available = True\n",
    "    print(\"✅ Plotly imports successful with notebook renderer\")\n",
    "except ImportError as e:\n",
    "    print(f\"⚠️ Plotly not available: {e}\")\n",
    "    print(\"Will use matplotlib fallbacks\")\n",
    "\n",
    "# Statistical analysis\n",
    "try:\n",
    "    from scipy import stats\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "    print(\"✅ Statistical analysis imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error importing scipy/sklearn: {e}\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scipy', 'scikit-learn', '--break-system-packages', '--quiet'])\n",
    "    from scipy import stats\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "    print(\"✅ Statistical analysis packages installed and imported\")\n",
    "\n",
    "print(f\"\\n🎉 All libraries imported successfully for 2016-2019 analysis!\")\n",
    "print(f\"FEV Framework Available: {'✅ Yes' if fev_available else '❌ No (using alternatives)'}\")\n",
    "print(f\"Plotly Available: {'✅ Yes' if plotly_available else '❌ No (using matplotlib)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Data Loading and Preprocessing for 2016-2019 Period",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Load gold futures data and filter to 2016-2019 period\ntry:\n    df = pd.read_csv('GCUSD_MAX_FROM_PERPLEXITY.csv')\n    print(\"✅ Data loaded successfully\")\nexcept FileNotFoundError:\n    print(\"❌ Error: GCUSD_MAX_FROM_PERPLEXITY.csv not found\")\n    print(\"Please ensure the data file is in the current directory.\")\n    raise FileNotFoundError(\"Data file required for 2016-2019 analysis\")\n\n# Display basic info about full dataset\nprint(f\"Full dataset shape: {df.shape}\")\nprint(f\"Columns: {df.columns.tolist()}\")\nprint(f\"Full date range: {df['Date'].min()} to {df['Date'].max()}\")\n\n# Check data availability for 2016-2019\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.sort_values('Date').reset_index(drop=True)\ndf = df.set_index('Date')\n\n# Filter for 2016-2019 data using the specified format\nstart_date = '2016-01-01'\nend_date = '2019-12-31'\nmask = (df.index >= start_date) & (df.index <= end_date)\ndf = df[mask]\n\n# Reset index to get Date as column again\ndf = df.reset_index()\ndata_2016_2019 = df.copy()\n\nprint(f\"\\n📅 2016-2019 PERIOD DATA:\")\nprint(f\"Filtered dataset shape: {data_2016_2019.shape}\")\nprint(f\"Date range: {data_2016_2019['Date'].min()} to {data_2016_2019['Date'].max()}\")\nprint(f\"Number of trading days: {len(data_2016_2019)}\")\n\n# Verify sufficient data for analysis\nif len(data_2016_2019) < 300:\n    print(f\"❌ Error: Only {len(data_2016_2019)} days of data available\")\n    print(\"Insufficient data for robust analysis. Need at least 300 days.\")\n    raise ValueError(\"Insufficient data for 2016-2019 analysis\")\nelif len(data_2016_2019) >= 1000:\n    print(f\"✅ Excellent: {len(data_2016_2019)} days provides sufficient data for robust analysis\")\nelse:\n    print(f\"✅ Good: {len(data_2016_2019)} days provides adequate data for analysis\")\n\nprint(f\"\\nFirst few rows of 2016-2019 data:\")\nprint(data_2016_2019.head())\nprint(f\"\\nLast few rows of 2016-2019 data:\")\nprint(data_2016_2019.tail())"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Data preprocessing for 2016-2019 period\ndef preprocess_data_2016_2019(df):\n    \"\"\"\n    Preprocess gold futures data for 2016-2019 time series analysis\n    \"\"\"\n    # Create a copy\n    data = df.copy()\n    \n    # Date is already converted and sorted\n    # Handle missing values using forward fill\n    data = data.ffill()\n    \n    # Create target variable (next day's close price)\n    data['Target'] = data['Close'].shift(-1)\n    \n    # Remove last row (no target available)\n    data = data[:-1].reset_index(drop=True)\n    \n    return data\n\n# Preprocess the 2016-2019 data\ndata = preprocess_data_2016_2019(data_2016_2019)\nprint(\"✅ 2016-2019 data preprocessing completed\")\n\nprint(f\"Final dataset shape: {data.shape}\")\nprint(f\"Date range: {data['Date'].min()} to {data['Date'].max()}\")\nprint(f\"Number of trading days: {len(data)}\")\n\n# Display basic statistics for 2016-2019 period\nprint(\"\\n2016-2019 Basic Statistics:\")\nprint(data[['Open', 'High', 'Low', 'Close', 'Volume']].describe())\n\n# Market characteristics analysis\nprint(\"\\n📊 MARKET CHARACTERISTICS (2016-2019):\")\nprint(f\"Price range: ${data['Close'].min():.2f} - ${data['Close'].max():.2f}\")\nprint(f\"Average daily volatility: {data['Close'].pct_change().std()*100:.2f}%\")\nprint(f\"Total return: {((data['Close'].iloc[-1] / data['Close'].iloc[0]) - 1)*100:.1f}%\")\n\n# Calculate volatility by year for context\nyearly_volatility = {}\nfor year in range(2016, 2020):\n    year_data = data[data['Date'].dt.year == year]\n    if len(year_data) > 1:\n        vol = year_data['Close'].pct_change().std() * np.sqrt(252) * 100\n        yearly_volatility[year] = vol\n\nprint(f\"\\nYearly Volatility Analysis:\")\nfor year, vol in yearly_volatility.items():\n    print(f\"  {year}: {vol:.1f}% annualized\")\n\n# Period context\nprint(f\"\\n📋 PERIOD CONTEXT:\")\nprint(f\"2016-2019 represents stable market conditions:\")\nprint(f\"  - Pre-COVID stable economic environment\")\nprint(f\"  - Gradual economic growth with low volatility\")\nprint(f\"  - Consistent market patterns\")\nprint(f\"  - Optimal conditions for pattern recognition models\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Market Regime Analysis: 2016-2019 Stable Period",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Market regime analysis for 2016-2019 stable period\nprint(\"📈 MARKET REGIME ANALYSIS: 2016-2019 STABLE PERIOD\")\nprint(\"=\" * 70)\n\ndef analyze_market_regime(data, period_name):\n    \"\"\"\n    Analyze market characteristics for a given period\n    \"\"\"\n    returns = data['Close'].pct_change().dropna()\n    \n    analysis = {\n        'period': period_name,\n        'trading_days': len(data),\n        'price_start': data['Close'].iloc[0],\n        'price_end': data['Close'].iloc[-1],\n        'total_return': ((data['Close'].iloc[-1] / data['Close'].iloc[0]) - 1) * 100,\n        'volatility': returns.std() * np.sqrt(252) * 100,  # Annualized volatility\n        'daily_volatility': returns.std() * 100,\n        'skewness': returns.skew(),\n        'kurtosis': returns.kurtosis(),\n        'max_drawdown': ((data['Close'] / data['Close'].cummax()) - 1).min() * 100,\n        'positive_days': (returns > 0).mean() * 100,\n        'large_moves': (np.abs(returns) > 0.02).mean() * 100,  # Days with >2% moves\n        'price_range': data['Close'].max() - data['Close'].min(),\n        'avg_volume': data['Volume'].mean()\n    }\n    \n    return analysis\n\n# Analyze the full 2016-2019 period\nregime_2016_2019 = analyze_market_regime(data_2016_2019, \"2016-2019\")\n\nprint(f\"\\n📊 COMPREHENSIVE MARKET ANALYSIS (2016-2019):\")\nprint(f\"Trading Days: {regime_2016_2019['trading_days']}\")\nprint(f\"Price Range: ${regime_2016_2019['price_start']:.2f} - ${regime_2016_2019['price_end']:.2f}\")\nprint(f\"Total Return: {regime_2016_2019['total_return']:.1f}%\")\nprint(f\"Annualized Volatility: {regime_2016_2019['volatility']:.1f}%\")\nprint(f\"Daily Volatility: {regime_2016_2019['daily_volatility']:.2f}%\")\nprint(f\"Skewness: {regime_2016_2019['skewness']:.2f}\")\nprint(f\"Kurtosis: {regime_2016_2019['kurtosis']:.2f}\")\nprint(f\"Max Drawdown: {regime_2016_2019['max_drawdown']:.1f}%\")\nprint(f\"Positive Days: {regime_2016_2019['positive_days']:.1f}%\")\nprint(f\"Large Moves (>2%): {regime_2016_2019['large_moves']:.1f}%\")\n\n# Break down by sub-periods for regime analysis\nsub_periods = {\n    '2016': data_2016_2019[data_2016_2019['Date'].dt.year == 2016],\n    '2017': data_2016_2019[data_2016_2019['Date'].dt.year == 2017],\n    '2018': data_2016_2019[data_2016_2019['Date'].dt.year == 2018],\n    '2019': data_2016_2019[data_2016_2019['Date'].dt.year == 2019]\n}\n\nprint(f\"\\n📅 YEARLY BREAKDOWN:\")\nprint(f\"{'Year':<6} {'Days':<6} {'Return':<8} {'Volatility':<12} {'Large Moves':<12}\")\nprint(\"-\" * 50)\n\nfor year, year_data in sub_periods.items():\n    if len(year_data) > 1:\n        regime = analyze_market_regime(year_data, year)\n        print(f\"{year:<6} {regime['trading_days']:<6} {regime['total_return']:<8.1f}% {regime['volatility']:<12.1f}% {regime['large_moves']:<12.1f}%\")\n\n# Market regime context\nprint(f\"\\n🔍 MARKET REGIME INSIGHTS:\")\nprint(\"-\" * 50)\nprint(f\"1. 📈 2016: Post-financial crisis recovery period\")\nprint(f\"2. 🚀 2017: Stable economic growth with low volatility\")\nprint(f\"3. 📊 2018: Gradual interest rate normalization\")\nprint(f\"4. 💼 2019: Pre-COVID stable market conditions\")\n\n# Hypothesis for Chronos performance\nprint(f\"\\n💡 CHRONOS PERFORMANCE HYPOTHESIS:\")\nprint(\"-\" * 50)\nprint(f\"✅ Stable 4-year period with consistent market dynamics\")\nprint(f\"✅ Lower volatility favors sophisticated pattern recognition\")\nprint(f\"✅ Gradual price movements support model learning\")\nprint(f\"✅ Optimal conditions for transformer-based forecasting\")\n\nif regime_2016_2019['volatility'] < 20:\n    print(f\"✅ Low volatility period should favor Chronos over naive baseline\")\n    print(f\"✅ Stable patterns enable better model performance\")\nelse:\n    print(f\"⚠️ Higher than expected volatility may challenge models\")\n    print(f\"⚠️ Naive baseline may still perform competitively\")\n\nprint(f\"\\n📋 ANALYSIS READY: Proceeding with comprehensive 2016-2019 Chronos evaluation...\")\nprint(f\"Analysis period: {len(data)} trading days from {data['Date'].min()} to {data['Date'].max()}\")\nprint(f\"Expected outcome: Chronos should outperform naive baseline in stable conditions\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Load 2020-2021 Results for Comparison",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing 2020-2021 results for comparison\n",
    "print(\"📁 Loading 2020-2021 results for comparative analysis...\")\n",
    "\n",
    "try:\n",
    "    # Try to load previous results\n",
    "    results_2020_2021 = pd.read_csv('gold_futures_forecast_metrics.csv', index_col=0)\n",
    "    print(\"✅ 2020-2021 results loaded successfully\")\n",
    "    print(f\"Available models: {list(results_2020_2021.index)}\")\n",
    "    \n",
    "    # Display key 2020-2021 results for reference\n",
    "    print(f\"\\n📊 2020-2021 REFERENCE RESULTS:\")\n",
    "    print(f\"{'Model':<20} {'MASE':<8} {'MAE':<8} {'Dir.Acc':<10} {'RMSE':<8}\")\n",
    "    print(\"-\" * 60)\n",
    "    for model in results_2020_2021.index:\n",
    "        row = results_2020_2021.loc[model]\n",
    "        mase = row['MASE'] if 'MASE' in row else 'N/A'\n",
    "        mae = row['MAE'] if 'MAE' in row else 'N/A'\n",
    "        dir_acc = row['Directional_Accuracy'] if 'Directional_Accuracy' in row else 'N/A'\n",
    "        rmse = row['RMSE'] if 'RMSE' in row else 'N/A'\n",
    "        print(f\"{model:<20} {mase:<8} {mae:<8.2f} {dir_acc:<10} {rmse:<8.2f}\")\n",
    "    \n",
    "    # Key findings from 2020-2021\n",
    "    naive_mase_2021 = results_2020_2021.loc['Naive', 'MASE'] if 'Naive' in results_2020_2021.index else None\n",
    "    chronos_mase_2021 = results_2020_2021.loc['Chronos', 'MASE'] if 'Chronos' in results_2020_2021.index else None\n",
    "    \n",
    "    if naive_mase_2021 and chronos_mase_2021:\n",
    "        performance_gap_2021 = ((chronos_mase_2021 - naive_mase_2021) / naive_mase_2021) * 100\n",
    "        print(f\"\\n🎯 2020-2021 KEY FINDING: Chronos MASE was {performance_gap_2021:.1f}% behind naive baseline\")\n",
    "        print(f\"   Naive: {naive_mase_2021:.4f} vs Chronos: {chronos_mase_2021:.4f}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ Previous 2020-2021 results not found\")\n",
    "    print(\"Will generate reference metrics for comparison after 2016-2019 analysis\")\n",
    "    results_2020_2021 = None\n",
    "    \n",
    "print(f\"\\n✅ Ready to run 2016-2019 analysis and compare with 2020-2021 period\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Run Complete 2016-2019 Analysis",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Complete 2016-2019 Chronos Analysis Implementation\nprint(\"🚀 EXECUTING COMPLETE 2016-2019 CHRONOS ANALYSIS\")\nprint(\"=\" * 70)\n\nimport time\nfrom typing import Dict, List, Tuple, Optional\nimport traceback\n\n# Define evaluation metrics functions\ndef calculate_mase(y_true: np.ndarray, y_pred: np.ndarray, y_train: np.ndarray) -> float:\n    \"\"\"Calculate Mean Absolute Scaled Error (MASE)\"\"\"\n    if len(y_train) < 2:\n        return np.nan\n    \n    # Calculate naive forecast MAE on training data\n    naive_mae = np.mean(np.abs(np.diff(y_train)))\n    \n    if naive_mae == 0:\n        return np.nan\n    \n    # Calculate forecast MAE\n    forecast_mae = np.mean(np.abs(y_true - y_pred))\n    \n    return forecast_mae / naive_mae\n\ndef calculate_directional_accuracy(y_true: np.ndarray, y_pred: np.ndarray, y_prev: np.ndarray) -> float:\n    \"\"\"Calculate directional accuracy (percentage of correct direction predictions)\"\"\"\n    if len(y_true) != len(y_pred) or len(y_true) != len(y_prev):\n        return np.nan\n    \n    actual_direction = np.sign(y_true - y_prev)\n    predicted_direction = np.sign(y_pred - y_prev)\n    \n    correct_predictions = (actual_direction == predicted_direction).sum()\n    total_predictions = len(y_true)\n    \n    return (correct_predictions / total_predictions) * 100\n\ndef calculate_comprehensive_metrics(y_true: np.ndarray, y_pred: np.ndarray, \n                                  y_train: np.ndarray, y_prev: np.ndarray) -> Dict:\n    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n    \n    # Remove any NaN values\n    mask = ~(np.isnan(y_true) | np.isnan(y_pred))\n    y_true_clean = y_true[mask]\n    y_pred_clean = y_pred[mask]\n    y_prev_clean = y_prev[mask]\n    \n    if len(y_true_clean) == 0:\n        return {\n            'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan, 'MASE': np.nan,\n            'Directional_Accuracy': np.nan, 'MSE': np.nan, 'Count': 0\n        }\n    \n    try:\n        mae = mean_absolute_error(y_true_clean, y_pred_clean)\n        rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n        mse = mean_squared_error(y_true_clean, y_pred_clean)\n        \n        # MAPE with handling for zero values\n        mape = np.mean(np.abs((y_true_clean - y_pred_clean) / np.maximum(np.abs(y_true_clean), 1e-8))) * 100\n        \n        mase = calculate_mase(y_true_clean, y_pred_clean, y_train)\n        dir_acc = calculate_directional_accuracy(y_true_clean, y_pred_clean, y_prev_clean)\n        \n        return {\n            'MAE': mae,\n            'RMSE': rmse,\n            'MAPE': mape,\n            'MASE': mase,\n            'Directional_Accuracy': dir_acc,\n            'MSE': mse,\n            'Count': len(y_true_clean)\n        }\n    except Exception as e:\n        print(f\"Error calculating metrics: {e}\")\n        return {\n            'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan, 'MASE': np.nan,\n            'Directional_Accuracy': np.nan, 'MSE': np.nan, 'Count': 0\n        }\n\n# Load Chronos model\nprint(\"📥 Loading Chronos model...\")\ntry:\n    model_name = \"amazon/chronos-bolt-base\"\n    pipeline = BaseChronosPipeline.from_pretrained(model_name)\n    print(f\"✅ Loaded {model_name} successfully\")\nexcept Exception as e:\n    print(f\"❌ Error loading Chronos model: {e}\")\n    print(\"Trying alternative model...\")\n    try:\n        model_name = \"amazon/chronos-t5-base\"\n        pipeline = BaseChronosPipeline.from_pretrained(model_name)\n        print(f\"✅ Loaded {model_name} successfully\")\n    except Exception as e2:\n        print(f\"❌ Failed to load any Chronos model: {e2}\")\n        raise\n\n# Define forecasting functions\ndef generate_chronos_forecast(pipeline, historical_data: np.ndarray, \n                             prediction_length: int = 1, num_samples: int = 100) -> np.ndarray:\n    \"\"\"Generate Chronos forecast\"\"\"\n    try:\n        # Convert to tensor\n        historical_tensor = torch.tensor(historical_data, dtype=torch.float32).unsqueeze(0)\n        \n        # Generate forecast\n        forecast = pipeline.predict(\n            context=historical_tensor,\n            prediction_length=prediction_length,\n            num_samples=num_samples\n        )\n        \n        # Get median forecast\n        forecast_median = forecast.median(dim=1).values\n        return forecast_median.numpy().flatten()\n    \n    except Exception as e:\n        print(f\"Error in Chronos forecast: {e}\")\n        return np.array([np.nan] * prediction_length)\n\ndef generate_naive_forecast(historical_data: np.ndarray, prediction_length: int = 1) -> np.ndarray:\n    \"\"\"Generate naive forecast (last value)\"\"\"\n    if len(historical_data) == 0:\n        return np.array([np.nan] * prediction_length)\n    return np.array([historical_data[-1]] * prediction_length)\n\ndef generate_ma_forecast(historical_data: np.ndarray, window: int = 5, \n                        prediction_length: int = 1) -> np.ndarray:\n    \"\"\"Generate moving average forecast\"\"\"\n    if len(historical_data) < window:\n        return generate_naive_forecast(historical_data, prediction_length)\n    \n    ma_value = np.mean(historical_data[-window:])\n    return np.array([ma_value] * prediction_length)\n\ndef generate_linear_trend_forecast(historical_data: np.ndarray, window: int = 10, \n                                  prediction_length: int = 1) -> np.ndarray:\n    \"\"\"Generate linear trend forecast\"\"\"\n    if len(historical_data) < window:\n        return generate_naive_forecast(historical_data, prediction_length)\n    \n    try:\n        # Use last 'window' points for trend calculation\n        recent_data = historical_data[-window:]\n        x = np.arange(len(recent_data))\n        \n        # Fit linear trend\n        coeffs = np.polyfit(x, recent_data, 1)\n        \n        # Predict next value(s)\n        predictions = []\n        for i in range(prediction_length):\n            pred = coeffs[0] * (len(recent_data) + i) + coeffs[1]\n            predictions.append(pred)\n        \n        return np.array(predictions)\n    \n    except Exception as e:\n        print(f\"Error in linear trend forecast: {e}\")\n        return generate_naive_forecast(historical_data, prediction_length)\n\n# Setup rolling window evaluation\nprint(\"🔄 Setting up rolling window evaluation...\")\n\n# Configuration for 2016-2019 analysis\nconfig = {\n    'context_window': 126,  # ~6 months of trading days\n    'prediction_length': 1,\n    'start_index': 200,     # Start after sufficient history\n    'min_history': 200,     # Minimum history required\n    'num_samples': 100,     # For Chronos probabilistic forecasting\n    'models': ['Chronos', 'Naive', 'Moving_Average', 'Linear_Trend']\n}\n\nprint(f\"📊 Analysis Configuration:\")\nfor key, value in config.items():\n    print(f\"   {key}: {value}\")\n\n# Initialize results storage\nresults = {model: {'predictions': [], 'actuals': [], 'dates': [], 'errors': []} \n          for model in config['models']}\n\n# Rolling window evaluation\nprint(f\"\\n🔄 Starting rolling window evaluation...\")\nprint(f\"Total evaluation points: {len(data) - config['start_index']}\")\n\nstart_time = time.time()\nprogress_interval = 50\n\nfor i in range(config['start_index'], len(data)):\n    # Progress reporting\n    if (i - config['start_index']) % progress_interval == 0:\n        progress = ((i - config['start_index']) / (len(data) - config['start_index'])) * 100\n        elapsed = time.time() - start_time\n        print(f\"Progress: {progress:.1f}% ({i - config['start_index']}/{len(data) - config['start_index']}) \"\n              f\"- Elapsed: {elapsed:.1f}s\")\n    \n    # Get historical data\n    start_idx = max(0, i - config['context_window'])\n    historical_data = data.iloc[start_idx:i]['Close'].values\n    \n    # Skip if insufficient history\n    if len(historical_data) < config['min_history']:\n        continue\n    \n    # Get actual value\n    actual_value = data.iloc[i]['Close']\n    evaluation_date = data.iloc[i]['Date']\n    \n    # Get previous value for directional accuracy\n    prev_value = data.iloc[i-1]['Close'] if i > 0 else actual_value\n    \n    # Generate forecasts for each model\n    for model_name in config['models']:\n        try:\n            if model_name == 'Chronos':\n                pred = generate_chronos_forecast(pipeline, historical_data, \n                                               config['prediction_length'], \n                                               config['num_samples'])\n            elif model_name == 'Naive':\n                pred = generate_naive_forecast(historical_data, config['prediction_length'])\n            elif model_name == 'Moving_Average':\n                pred = generate_ma_forecast(historical_data, window=20, \n                                           prediction_length=config['prediction_length'])\n            elif model_name == 'Linear_Trend':\n                pred = generate_linear_trend_forecast(historical_data, window=20, \n                                                    prediction_length=config['prediction_length'])\n            \n            # Store results\n            if len(pred) > 0 and not np.isnan(pred[0]):\n                results[model_name]['predictions'].append(pred[0])\n                results[model_name]['actuals'].append(actual_value)\n                results[model_name]['dates'].append(evaluation_date)\n                results[model_name]['errors'].append(abs(pred[0] - actual_value))\n            else:\n                # Handle failed predictions\n                results[model_name]['predictions'].append(np.nan)\n                results[model_name]['actuals'].append(actual_value)\n                results[model_name]['dates'].append(evaluation_date)\n                results[model_name]['errors'].append(np.nan)\n        \n        except Exception as e:\n            print(f\"Error with {model_name} at step {i}: {e}\")\n            results[model_name]['predictions'].append(np.nan)\n            results[model_name]['actuals'].append(actual_value)\n            results[model_name]['dates'].append(evaluation_date)\n            results[model_name]['errors'].append(np.nan)\n\ntotal_time = time.time() - start_time\nprint(f\"\\n✅ Evaluation completed in {total_time:.1f} seconds\")\n\n# Calculate comprehensive metrics\nprint(\"\\n📊 Calculating comprehensive metrics...\")\nmetrics_results = {}\n\nfor model_name in config['models']:\n    model_results = results[model_name]\n    \n    # Convert to numpy arrays\n    predictions = np.array(model_results['predictions'])\n    actuals = np.array(model_results['actuals'])\n    \n    # Get training data for MASE calculation\n    training_data = data.iloc[:config['start_index']]['Close'].values\n    \n    # Get previous values for directional accuracy\n    prev_values = np.array([data.iloc[i-1]['Close'] for i in range(config['start_index'], len(data)) \n                           if i < len(data)])[:len(predictions)]\n    \n    # Calculate metrics\n    metrics = calculate_comprehensive_metrics(actuals, predictions, training_data, prev_values)\n    metrics_results[model_name] = metrics\n    \n    print(f\"\\n{model_name} Results:\")\n    for metric, value in metrics.items():\n        if isinstance(value, float):\n            print(f\"   {metric}: {value:.4f}\")\n        else:\n            print(f\"   {metric}: {value}\")\n\n# Create results DataFrame\nresults_df = pd.DataFrame(metrics_results).T\nresults_df = results_df.round(4)\n\nprint(f\"\\n📈 2016-2019 FINAL RESULTS:\")\nprint(\"=\" * 70)\nprint(results_df)\n\n# Save results\nresults_df.to_csv('gold_futures_forecast_2016_2019_metrics.csv')\nprint(f\"\\n✅ Results saved to 'gold_futures_forecast_2016_2019_metrics.csv'\")\n\n# Save detailed predictions\npredictions_df = pd.DataFrame({\n    'Date': results['Chronos']['dates'],\n    'Actual': results['Chronos']['actuals'],\n    'Chronos': results['Chronos']['predictions'],\n    'Naive': results['Naive']['predictions'],\n    'Moving_Average': results['Moving_Average']['predictions'],\n    'Linear_Trend': results['Linear_Trend']['predictions']\n})\n\npredictions_df.to_csv('gold_futures_forecast_2016_2019_predictions.csv', index=False)\nprint(f\"✅ Detailed predictions saved to 'gold_futures_forecast_2016_2019_predictions.csv'\")\n\nprint(f\"\\n🎉 2016-2019 Analysis Complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Load and Compare with 2020-2021 Results\nprint(\"📊 LOADING 2020-2021 RESULTS FOR COMPREHENSIVE COMPARISON\")\nprint(\"=\" * 70)\n\n# Try to load 2020-2021 results for comparison\ntry:\n    results_2020_2021 = pd.read_csv('gold_futures_forecast_metrics.csv', index_col=0)\n    print(\"✅ 2020-2021 results loaded successfully\")\n    \n    # Create comprehensive comparison\n    print(f\"\\n🔍 COMPREHENSIVE MARKET REGIME COMPARISON\")\n    print(\"=\" * 50)\n    \n    # Create comparison table\n    comparison_data = []\n    \n    # Get models that exist in both periods\n    common_models = set(results_df.index) & set(results_2020_2021.index)\n    print(f\"Common models for comparison: {list(common_models)}\")\n    \n    for model in common_models:\n        metrics_2016_2019 = results_df.loc[model]\n        metrics_2020_2021 = results_2020_2021.loc[model]\n        \n        comparison_data.append({\n            'Model': model,\n            'MASE_2016_2019': metrics_2016_2019['MASE'],\n            'MASE_2020_2021': metrics_2020_2021['MASE'],\n            'MASE_Improvement': metrics_2016_2019['MASE'] - metrics_2020_2021['MASE'],\n            'MASE_Percent_Change': ((metrics_2016_2019['MASE'] - metrics_2020_2021['MASE']) / metrics_2020_2021['MASE']) * 100,\n            'MAE_2016_2019': metrics_2016_2019['MAE'],\n            'MAE_2020_2021': metrics_2020_2021['MAE'],\n            'Dir_Acc_2016_2019': metrics_2016_2019['Directional_Accuracy'],\n            'Dir_Acc_2020_2021': metrics_2020_2021['Directional_Accuracy'],\n            'Dir_Acc_Improvement': metrics_2016_2019['Directional_Accuracy'] - metrics_2020_2021['Directional_Accuracy']\n        })\n    \n    if comparison_data:\n        comparison_df = pd.DataFrame(comparison_data)\n        comparison_df = comparison_df.round(4)\n        \n        print(f\"\\n📈 DETAILED COMPARISON TABLE:\")\n        print(comparison_df.to_string(index=False))\n        \n        # Save comparison results\n        comparison_df.to_csv('market_regime_comparison_2016_2019_vs_2020_2021.csv', index=False)\n        print(f\"\\n✅ Comparison saved to 'market_regime_comparison_2016_2019_vs_2020_2021.csv'\")\n        \n        # Key insights\n        print(f\"\\n🎯 KEY COMPARATIVE INSIGHTS:\")\n        print(\"=\" * 50)\n        \n        if 'Naive' in comparison_df['Model'].values:\n            naive_row = comparison_df[comparison_df['Model'] == 'Naive'].iloc[0]\n            print(f\"1. 📊 Naive Baseline Performance:\")\n            print(f\"   - 2016-2019 MASE: {naive_row['MASE_2016_2019']:.4f}\")\n            print(f\"   - 2020-2021 MASE: {naive_row['MASE_2020_2021']:.4f}\")\n            print(f\"   - Change: {naive_row['MASE_Percent_Change']:.1f}%\")\n            print(f\"   - Interpretation: Naive was {'better' if naive_row['MASE_Improvement'] < 0 else 'worse'} in 2016-2019\")\n        \n        if 'Chronos' in comparison_df['Model'].values:\n            chronos_row = comparison_df[comparison_df['Model'] == 'Chronos'].iloc[0]\n            print(f\"\\n2. 🤖 Chronos Performance:\")\n            print(f\"   - 2016-2019 MASE: {chronos_row['MASE_2016_2019']:.4f}\")\n            print(f\"   - 2020-2021 MASE: {chronos_row['MASE_2020_2021']:.4f}\")\n            print(f\"   - Change: {chronos_row['MASE_Percent_Change']:.1f}%\")\n            print(f\"   - Interpretation: Chronos was {'better' if chronos_row['MASE_Improvement'] < 0 else 'worse'} in 2016-2019\")\n        \n        # Market regime effect on relative performance\n        if 'Naive' in comparison_df['Model'].values and 'Chronos' in comparison_df['Model'].values:\n            naive_2016 = comparison_df[comparison_df['Model'] == 'Naive']['MASE_2016_2019'].iloc[0]\n            chronos_2016 = comparison_df[comparison_df['Model'] == 'Chronos']['MASE_2016_2019'].iloc[0]\n            gap_2016 = ((chronos_2016 - naive_2016) / naive_2016) * 100\n            \n            naive_2021 = comparison_df[comparison_df['Model'] == 'Naive']['MASE_2020_2021'].iloc[0]\n            chronos_2021 = comparison_df[comparison_df['Model'] == 'Chronos']['MASE_2020_2021'].iloc[0]\n            gap_2021 = ((chronos_2021 - naive_2021) / naive_2021) * 100\n            \n            print(f\"\\n3. 🔄 Market Regime Impact on Chronos vs Naive:\")\n            print(f\"   - 2016-2019 gap: {gap_2016:.1f}% ({'behind' if gap_2016 > 0 else 'ahead'})\")\n            print(f\"   - 2020-2021 gap: {gap_2021:.1f}% ({'behind' if gap_2021 > 0 else 'ahead'})\")\n            print(f\"   - Regime effect: {gap_2016 - gap_2021:.1f} percentage points\")\n            \n            if gap_2016 < gap_2021:\n                print(f\"   ✅ Chronos performed relatively better in stable markets (2016-2019)\")\n                print(f\"   📈 Market volatility negatively impacts Chronos relative performance\")\n            else:\n                print(f\"   ❌ Chronos did not perform relatively better in stable markets\")\n                print(f\"   📉 Stable markets did not provide expected advantage for sophisticated models\")\n        \n        # Directional accuracy insights\n        print(f\"\\n4. 🎯 Directional Accuracy Comparison:\")\n        for model in ['Chronos', 'Naive']:\n            if model in comparison_df['Model'].values:\n                row = comparison_df[comparison_df['Model'] == model].iloc[0]\n                print(f\"   - {model}: {row['Dir_Acc_2016_2019']:.1f}% (2016-2019) vs {row['Dir_Acc_2020_2021']:.1f}% (2020-2021)\")\n                print(f\"     Change: {row['Dir_Acc_Improvement']:.1f} percentage points\")\n        \n        # Create visualization\n        if plotly_available:\n            print(f\"\\n📊 Creating interactive comparison visualization...\")\n            \n            fig = make_subplots(\n                rows=2, cols=2,\n                subplot_titles=('MASE Comparison', 'Directional Accuracy Comparison', \n                               'Performance Change', 'Market Regime Effect'),\n                specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n                       [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n            )\n            \n            models = comparison_df['Model'].tolist()\n            \n            # MASE comparison\n            fig.add_trace(go.Bar(name='2016-2019 (Stable)', x=models, y=comparison_df['MASE_2016_2019'],\n                                marker_color='lightblue'), row=1, col=1)\n            fig.add_trace(go.Bar(name='2020-2021 (Volatile)', x=models, y=comparison_df['MASE_2020_2021'],\n                                marker_color='orange'), row=1, col=1)\n            \n            # Directional accuracy comparison\n            fig.add_trace(go.Bar(name='2016-2019 (Stable)', x=models, y=comparison_df['Dir_Acc_2016_2019'],\n                                marker_color='lightgreen', showlegend=False), row=1, col=2)\n            fig.add_trace(go.Bar(name='2020-2021 (Volatile)', x=models, y=comparison_df['Dir_Acc_2020_2021'],\n                                marker_color='red', showlegend=False), row=1, col=2)\n            \n            # Performance change\n            fig.add_trace(go.Bar(name='MASE Change (%)', x=models, y=comparison_df['MASE_Percent_Change'],\n                                marker_color='purple', showlegend=False), row=2, col=1)\n            \n            # Market regime effect on Chronos vs Naive gap\n            if 'Naive' in models and 'Chronos' in models:\n                regime_effect = [gap_2016, gap_2021]\n                regime_labels = ['2016-2019\\n(Stable)', '2020-2021\\n(Volatile)']\n                fig.add_trace(go.Bar(name='Chronos vs Naive Gap (%)', x=regime_labels, y=regime_effect,\n                                    marker_color=['lightcoral', 'darkred'], showlegend=False), row=2, col=2)\n            \n            fig.update_layout(height=800, title_text=\"Market Regime Impact: 2016-2019 (Stable) vs 2020-2021 (Volatile)\")\n            fig.show()\n        \n        print(f\"\\n💡 PRACTICAL IMPLICATIONS:\")\n        print(\"=\" * 50)\n        print(f\"1. Market regime significantly impacts model performance\")\n        print(f\"2. {'Stable' if gap_2016 < gap_2021 else 'Volatile'} markets favor sophisticated models\")\n        print(f\"3. Ensemble strategies should consider market regime detection\")\n        print(f\"4. Model selection criteria should adapt to market volatility\")\n        print(f\"5. Naive baseline strength varies with market conditions\")\n        \n    else:\n        print(\"❌ No common models found for comparison\")\n        \nexcept FileNotFoundError:\n    print(\"⚠️ 2020-2021 results not found - unable to perform comparison\")\n    print(\"Run the 2020-2021 analysis first to enable full comparison\")\n    print(\"Current analysis provides 2016-2019 baseline for future comparisons\")\n    \nexcept Exception as e:\n    print(f\"❌ Error loading 2020-2021 results: {e}\")\n    print(\"Continuing with 2016-2019 analysis only\")\n\nprint(f\"\\n✅ Comparison analysis complete!\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive Results Analysis and Visualization\nprint(\"📊 COMPREHENSIVE RESULTS ANALYSIS AND VISUALIZATION\")\nprint(\"=\" * 70)\n\n# Create comprehensive visualization\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\nfig.suptitle('2016-2019 Gold Futures Forecasting Analysis', fontsize=16, fontweight='bold')\n\n# 1. Model Performance Comparison\nax1 = axes[0, 0]\nmodels = results_df.index.tolist()\nmase_values = results_df['MASE'].values\ncolors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n\nbars = ax1.bar(models, mase_values, color=colors[:len(models)])\nax1.set_title('Model Performance (MASE)', fontweight='bold')\nax1.set_ylabel('MASE Score')\nax1.set_xlabel('Model')\nax1.tick_params(axis='x', rotation=45)\n\n# Add value labels on bars\nfor bar, value in zip(bars, mase_values):\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n             f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n\n# Add horizontal line at MASE = 1 (break-even with naive)\nax1.axhline(y=1.0, color='red', linestyle='--', alpha=0.7, label='Break-even')\nax1.legend()\n\n# 2. Directional Accuracy\nax2 = axes[0, 1]\ndir_acc_values = results_df['Directional_Accuracy'].values\nbars2 = ax2.bar(models, dir_acc_values, color=colors[:len(models)])\nax2.set_title('Directional Accuracy', fontweight='bold')\nax2.set_ylabel('Accuracy (%)')\nax2.set_xlabel('Model')\nax2.tick_params(axis='x', rotation=45)\n\n# Add value labels\nfor bar, value in zip(bars2, dir_acc_values):\n    height = bar.get_height()\n    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n             f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')\n\n# Add 50% line (random guess)\nax2.axhline(y=50.0, color='red', linestyle='--', alpha=0.7, label='Random (50%)')\nax2.legend()\n\n# 3. Prediction vs Actual (sample)\nax3 = axes[1, 0]\nif len(predictions_df) > 0:\n    # Plot last 120 days as sample\n    sample_size = min(120, len(predictions_df))\n    sample_data = predictions_df.tail(sample_size)\n    \n    ax3.plot(sample_data.index, sample_data['Actual'], 'k-', linewidth=2, label='Actual', alpha=0.8)\n    ax3.plot(sample_data.index, sample_data['Chronos'], 'r--', linewidth=1.5, label='Chronos', alpha=0.7)\n    ax3.plot(sample_data.index, sample_data['Naive'], 'b:', linewidth=1.5, label='Naive', alpha=0.7)\n    \n    ax3.set_title(f'Predictions vs Actual (Last {sample_size} Days)', fontweight='bold')\n    ax3.set_ylabel('Price ($)')\n    ax3.set_xlabel('Time Index')\n    ax3.legend()\n    ax3.grid(True, alpha=0.3)\n\n# 4. Error Distribution\nax4 = axes[1, 1]\nif len(predictions_df) > 0:\n    chronos_errors = np.abs(predictions_df['Actual'] - predictions_df['Chronos'])\n    naive_errors = np.abs(predictions_df['Actual'] - predictions_df['Naive'])\n    \n    ax4.hist(chronos_errors, bins=30, alpha=0.7, label='Chronos', color='red', density=True)\n    ax4.hist(naive_errors, bins=30, alpha=0.7, label='Naive', color='blue', density=True)\n    \n    ax4.set_title('Error Distribution', fontweight='bold')\n    ax4.set_xlabel('Absolute Error ($)')\n    ax4.set_ylabel('Density')\n    ax4.legend()\n    ax4.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Print key insights\nprint(f\"\\n🔍 KEY INSIGHTS FROM 2016-2019 ANALYSIS:\")\nprint(\"=\" * 50)\n\nbest_model = results_df.loc[results_df['MASE'].idxmin()]\nbest_model_name = results_df['MASE'].idxmin()\n\nprint(f\"1. 🏆 Best Model: {best_model_name}\")\nprint(f\"   - MASE: {best_model['MASE']:.4f}\")\nprint(f\"   - Directional Accuracy: {best_model['Directional_Accuracy']:.1f}%\")\nprint(f\"   - MAE: ${best_model['MAE']:.2f}\")\n\n# Compare with naive baseline\nif 'Naive' in results_df.index:\n    naive_mase = results_df.loc['Naive', 'MASE']\n    chronos_mase = results_df.loc['Chronos', 'MASE']\n    \n    improvement = ((naive_mase - chronos_mase) / naive_mase) * 100\n    print(f\"\\n2. 📊 Chronos vs Naive Baseline:\")\n    print(f\"   - Naive MASE: {naive_mase:.4f}\")\n    print(f\"   - Chronos MASE: {chronos_mase:.4f}\")\n    print(f\"   - Improvement: {improvement:.1f}%\")\n    \n    if improvement > 0:\n        print(f\"   ✅ Chronos outperforms naive baseline by {improvement:.1f}%\")\n    else:\n        print(f\"   ❌ Chronos underperforms naive baseline by {abs(improvement):.1f}%\")\n\n# Directional accuracy insights\nchronos_dir_acc = results_df.loc['Chronos', 'Directional_Accuracy']\nnaive_dir_acc = results_df.loc['Naive', 'Directional_Accuracy']\n\nprint(f\"\\n3. 🎯 Directional Accuracy Analysis:\")\nprint(f\"   - Chronos: {chronos_dir_acc:.1f}%\")\nprint(f\"   - Naive: {naive_dir_acc:.1f}%\")\n\nif chronos_dir_acc > 50:\n    print(f\"   ✅ Chronos shows directional skill ({chronos_dir_acc:.1f}% > 50%)\")\nelse:\n    print(f\"   ⚠️ Chronos directional accuracy below random ({chronos_dir_acc:.1f}% < 50%)\")\n\n# Market regime context\nprint(f\"\\n4. 📈 Market Regime Context (2016-2019):\")\nprint(f\"   - Period: Stable, low-volatility pre-COVID market\")\nprint(f\"   - Expectation: Favorable conditions for sophisticated models\")\nprint(f\"   - Gradual price movements and consistent patterns\")\nprint(f\"   - Result: {'Hypothesis confirmed' if improvement > 0 else 'Hypothesis challenged'}\")\n\n# Statistical significance (simple test)\nif len(predictions_df) > 0:\n    chronos_errors = np.abs(predictions_df['Actual'] - predictions_df['Chronos'])\n    naive_errors = np.abs(predictions_df['Actual'] - predictions_df['Naive'])\n    \n    # Paired t-test\n    try:\n        t_stat, p_value = stats.ttest_rel(chronos_errors, naive_errors)\n        print(f\"\\n5. 📊 Statistical Significance:\")\n        print(f\"   - T-statistic: {t_stat:.4f}\")\n        print(f\"   - P-value: {p_value:.4f}\")\n        print(f\"   - Significant: {'Yes' if p_value < 0.05 else 'No'} (α = 0.05)\")\n    except Exception as e:\n        print(f\"\\n5. 📊 Statistical test failed: {e}\")\n\n# Performance by year (if enough data)\nif len(predictions_df) > 0 and 'Date' in predictions_df.columns:\n    try:\n        predictions_df['Date'] = pd.to_datetime(predictions_df['Date'])\n        predictions_df['Year'] = predictions_df['Date'].dt.year\n        \n        print(f\"\\n6. 📅 Performance by Year:\")\n        for year in sorted(predictions_df['Year'].unique()):\n            year_data = predictions_df[predictions_df['Year'] == year]\n            if len(year_data) > 20:  # Minimum data points\n                year_mae_chronos = np.mean(np.abs(year_data['Actual'] - year_data['Chronos']))\n                year_mae_naive = np.mean(np.abs(year_data['Actual'] - year_data['Naive']))\n                year_improvement = ((year_mae_naive - year_mae_chronos) / year_mae_naive) * 100\n                print(f\"   - {year}: {year_improvement:.1f}% improvement over naive\")\n    except Exception as e:\n        print(f\"\\n6. 📅 Yearly breakdown failed: {e}\")\n\nprint(f\"\\n✅ 2016-2019 Analysis Complete - Stable market period evaluation!\")\nprint(f\"📋 Ready for comparison with volatile market periods (2020-2021)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Executive Summary and Conclusions\n\nThis notebook provides a comprehensive analysis of Chronos model performance on 2016-2019 gold futures data, enabling direct comparison with the 2020-2021 period analysis to understand market regime effects on forecasting performance.\n\n### Key Analysis Components:\n1. **Market Regime Analysis**: Quantitative comparison of market characteristics between 2016-2019 (stable) and 2020-2021 (volatile) periods\n2. **Identical Methodology**: Same evaluation framework ensures fair comparison across market regimes\n3. **Performance Comparison**: Direct model performance comparison to identify market-dependent patterns\n4. **Statistical Robustness**: Comprehensive metrics and significance testing\n5. **Practical Insights**: Market-dependent model selection and ensemble strategy guidance\n\n### Expected Outcomes:\n- **Market Regime Impact**: Quantified impact of market volatility on Chronos vs naive performance\n- **Optimal Configuration**: Best model settings for stable market conditions (2016-2019)\n- **Model Selection Criteria**: When to use sophisticated models vs simple baselines\n- **Ensemble Strategy**: Robust recommendations combining multiple approaches\n- **Regime Detection**: Insights for adaptive forecasting based on market conditions\n\n### Hypothesis Testing:\n**H1**: Chronos models perform better relative to naive baselines in stable markets (2016-2019) vs volatile markets (2020-2021)\n**H2**: Lower volatility periods favor pattern recognition capabilities of transformer-based models\n**H3**: Market regime significantly impacts optimal model configuration and performance gaps",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}