{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gold Futures Log Returns Forecasting with Chronos\n",
    "\n",
    "This notebook implements a log returns-based approach for forecasting gold futures prices using Chronos models.\n",
    "\n",
    "## Key Advantages of Log Returns Approach:\n",
    "- **Stationarity**: Log returns are typically stationary, unlike absolute prices\n",
    "- **Normality**: Better approximation to normal distribution\n",
    "- **Scale Independence**: Unit-free percentages, generalizable across time periods\n",
    "- **Financial Interpretation**: Direct relationship to risk metrics and portfolio theory\n",
    "\n",
    "## Analysis Structure:\n",
    "1. Data Loading and Log Return Calculation\n",
    "2. Statistical Analysis (Stationarity, Distribution)\n",
    "3. Chronos Model Configuration for Returns\n",
    "4. Model Training and Inference\n",
    "5. Price Reconstruction and Evaluation\n",
    "6. Comparison with Absolute Price Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Chronos imports\n",
    "from chronos import ChronosPipeline, ChronosBoltPipeline\n",
    "import torch\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "try:\n",
    "    from statsmodels.tsa.stattools import adfuller, kpss\n",
    "    STATSMODELS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"⚠️  statsmodels not found. Installing...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"statsmodels\"])\n",
    "    from statsmodels.tsa.stattools import adfuller, kpss\n",
    "    STATSMODELS_AVAILABLE = True\n",
    "\n",
    "# Custom utilities\n",
    "import sys\n",
    "sys.path.append('./utils')\n",
    "from log_return_helpers import (\n",
    "    calculate_log_returns,\n",
    "    test_stationarity,\n",
    "    reconstruct_prices,\n",
    "    calculate_return_metrics,\n",
    "    prepare_returns_for_chronos,\n",
    "    analyze_return_distribution\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except:\n",
    "    plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Log Return Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gold futures data\n",
    "data_path = '../gold_futures_analysis/GCUSD_MAX_FROM_PERPLEXITY.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Convert date column and set as index\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Sort by date\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns for different price series\n",
    "log_returns = {}\n",
    "price_columns = ['Open', 'High', 'Low', 'Close']\n",
    "\n",
    "for col in price_columns:\n",
    "    log_returns[f'{col}_returns'] = calculate_log_returns(df[col])\n",
    "\n",
    "# Focus on Close price returns for main analysis\n",
    "close_returns = log_returns['Close_returns']\n",
    "\n",
    "print(f\"Close returns shape: {close_returns.shape}\")\n",
    "print(f\"Returns date range: {close_returns.index.min()} to {close_returns.index.max()}\")\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(close_returns.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical Analysis of Log Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test stationarity\n",
    "stationarity_results = test_stationarity(close_returns)\n",
    "\n",
    "print(\"=== STATIONARITY TEST RESULTS ===\")\n",
    "print(f\"ADF Test:\")\n",
    "print(f\"  Statistic: {stationarity_results['adf_statistic']:.4f}\")\n",
    "print(f\"  P-value: {stationarity_results['adf_pvalue']:.4f}\")\n",
    "print(f\"  Is Stationary: {stationarity_results['adf_is_stationary']}\")\n",
    "\n",
    "print(f\"\\nKPSS Test:\")\n",
    "print(f\"  Statistic: {stationarity_results['kpss_statistic']:.4f}\")\n",
    "print(f\"  P-value: {stationarity_results['kpss_pvalue']:.4f}\")\n",
    "print(f\"  Is Stationary: {stationarity_results['kpss_is_stationary']}\")\n",
    "\n",
    "# Compare with price stationarity\n",
    "price_stationarity = test_stationarity(df['Close'])\n",
    "print(f\"\\n=== PRICE STATIONARITY (for comparison) ===\")\n",
    "print(f\"ADF P-value: {price_stationarity['adf_pvalue']:.4f}\")\n",
    "print(f\"Is Stationary: {price_stationarity['adf_is_stationary']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze return distribution\n",
    "distribution_stats = analyze_return_distribution(close_returns)\n",
    "\n",
    "print(\"=== RETURN DISTRIBUTION ANALYSIS ===\")\n",
    "print(f\"Mean: {distribution_stats['mean']:.6f}\")\n",
    "print(f\"Std Dev: {distribution_stats['std']:.6f}\")\n",
    "print(f\"Skewness: {distribution_stats['skewness']:.4f}\")\n",
    "print(f\"Kurtosis: {distribution_stats['kurtosis']:.4f}\")\n",
    "print(f\"\\nNormality Test:\")\n",
    "print(f\"  Jarque-Bera P-value: {distribution_stats['jarque_bera_pvalue']:.4f}\")\n",
    "print(f\"  Is Normal: {distribution_stats['is_normal']}\")\n",
    "\n",
    "print(f\"\\nPercentiles:\")\n",
    "for pct, value in distribution_stats['percentiles'].items():\n",
    "    print(f\"  {pct}: {value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of returns vs prices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Price series\n",
    "axes[0, 0].plot(df.index, df['Close'], linewidth=1)\n",
    "axes[0, 0].set_title('Gold Futures Close Price')\n",
    "axes[0, 0].set_ylabel('Price ($)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Log returns series\n",
    "axes[0, 1].plot(close_returns.index, close_returns, linewidth=0.8, alpha=0.7)\n",
    "axes[0, 1].set_title('Log Returns')\n",
    "axes[0, 1].set_ylabel('Log Return')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Return distribution\n",
    "axes[1, 0].hist(close_returns, bins=50, alpha=0.7, density=True)\n",
    "axes[1, 0].set_title('Log Returns Distribution')\n",
    "axes[1, 0].set_xlabel('Log Return')\n",
    "axes[1, 0].set_ylabel('Density')\n",
    "\n",
    "# Overlay normal distribution\n",
    "x = np.linspace(close_returns.min(), close_returns.max(), 100)\n",
    "normal_dist = stats.norm.pdf(x, close_returns.mean(), close_returns.std())\n",
    "axes[1, 0].plot(x, normal_dist, 'r-', linewidth=2, label='Normal Distribution')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(close_returns, dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].set_title('Q-Q Plot vs Normal Distribution')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary comparison\n",
    "print(\"\\n=== SUMMARY COMPARISON ===\")\n",
    "print(\"Price Series:\")\n",
    "print(f\"  Coefficient of Variation: {df['Close'].std() / df['Close'].mean():.4f}\")\n",
    "print(f\"  Is Stationary: {price_stationarity['adf_is_stationary']}\")\n",
    "print(f\"\\nLog Returns Series:\")\n",
    "print(f\"  Coefficient of Variation: {close_returns.std() / abs(close_returns.mean()):.4f}\")\n",
    "print(f\"  Is Stationary: {stationarity_results['adf_is_stationary']}\")\n",
    "print(f\"  Closer to Normal: {distribution_stats['is_normal']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chronos Model Configuration for Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration based on optimal settings from price analysis\n",
    "CONFIG = {\n",
    "    'models': {\n",
    "        'chronos_bolt_base': 'amazon/chronos-bolt-base',\n",
    "        'chronos_bolt_small': 'amazon/chronos-bolt-small',\n",
    "        'chronos_t5_base': 'amazon/chronos-t5-base'\n",
    "    },\n",
    "    'context_windows': [63, 126, 252],  # 3M, 6M, 12M trading days\n",
    "    'prediction_horizons': [1, 3, 7],   # 1D, 3D, 1W\n",
    "    'num_samples': 100,\n",
    "    'test_split_date': '2021-01-01',\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")\n",
    "print(f\"Available models: {list(CONFIG['models'].keys())}\")\n",
    "print(f\"Test split date: {CONFIG['test_split_date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training/testing\n",
    "split_date = pd.to_datetime(CONFIG['test_split_date'])\n",
    "\n",
    "train_returns = close_returns[close_returns.index < split_date]\n",
    "test_returns = close_returns[close_returns.index >= split_date]\n",
    "\n",
    "print(f\"Training period: {train_returns.index.min()} to {train_returns.index.max()}\")\n",
    "print(f\"Testing period: {test_returns.index.min()} to {test_returns.index.max()}\")\n",
    "print(f\"Training samples: {len(train_returns)}\")\n",
    "print(f\"Testing samples: {len(test_returns)}\")\n",
    "\n",
    "# Corresponding price data for reconstruction\n",
    "train_prices = df['Close'][df.index < split_date]\n",
    "test_prices = df['Close'][df.index >= split_date]\n",
    "\n",
    "print(f\"\\nLast training price: ${train_prices.iloc[-1]:.2f}\")\n",
    "print(f\"First test price: ${test_prices.iloc[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "models = {}\n",
    "\n",
    "for model_name, model_id in CONFIG['models'].items():\n",
    "    print(f\"Loading {model_name}...\")\n",
    "    if 'bolt' in model_name:\n",
    "        pipeline = ChronosBoltPipeline.from_pretrained(model_id, device_map=CONFIG['device'])\n",
    "    else:\n",
    "        pipeline = ChronosPipeline.from_pretrained(model_id, device_map=CONFIG['device'])\n",
    "    models[model_name] = pipeline\n",
    "    print(f\"  ✓ {model_name} loaded successfully\")\n",
    "\n",
    "print(f\"\\nLoaded {len(models)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systematic forecasting with different configurations\n",
    "results = []\n",
    "\n",
    "for model_name, pipeline in models.items():\n",
    "    for context_window in CONFIG['context_windows']:\n",
    "        for horizon in CONFIG['prediction_horizons']:\n",
    "            \n",
    "            print(f\"\\nRunning {model_name} - Context: {context_window} - Horizon: {horizon}\")\n",
    "            \n",
    "            # Prepare data\n",
    "            if len(train_returns) < context_window:\n",
    "                print(f\"  ⚠️  Insufficient training data for context window {context_window}\")\n",
    "                continue\n",
    "            \n",
    "            # Use training data for context\n",
    "            context_data = train_returns.iloc[-context_window:].values\n",
    "            \n",
    "            # Generate forecasts\n",
    "            try:\n",
    "                forecast = pipeline.predict(\n",
    "                    context=torch.tensor(context_data, dtype=torch.float32),\n",
    "                    prediction_length=horizon,\n",
    "                    num_samples=CONFIG['num_samples']\n",
    "                )\n",
    "                \n",
    "                # Extract predictions (mean across samples)\n",
    "                predictions = forecast[0].median(dim=0).values.numpy()\n",
    "                \n",
    "                # Get actual returns for comparison\n",
    "                actual_returns = test_returns.iloc[:horizon].values\n",
    "                \n",
    "                if len(actual_returns) == horizon:\n",
    "                    # Calculate return metrics\n",
    "                    return_metrics = calculate_return_metrics(\n",
    "                        pd.Series(actual_returns), \n",
    "                        pd.Series(predictions)\n",
    "                    )\n",
    "                    \n",
    "                    # Reconstruct prices\n",
    "                    initial_price = train_prices.iloc[-1]\n",
    "                    \n",
    "                    # Predicted prices\n",
    "                    predicted_prices = []\n",
    "                    current_price = initial_price\n",
    "                    for ret in predictions:\n",
    "                        current_price = current_price * np.exp(ret)\n",
    "                        predicted_prices.append(current_price)\n",
    "                    \n",
    "                    # Actual prices\n",
    "                    actual_prices = test_prices.iloc[:horizon].values\n",
    "                    \n",
    "                    # Price-based metrics\n",
    "                    price_mae = np.mean(np.abs(actual_prices - predicted_prices))\n",
    "                    price_mape = np.mean(np.abs((actual_prices - predicted_prices) / actual_prices)) * 100\n",
    "                    \n",
    "                    # Store results\n",
    "                    result = {\n",
    "                        'model': model_name,\n",
    "                        'context_window': context_window,\n",
    "                        'horizon': horizon,\n",
    "                        'return_mae': return_metrics['mae'],\n",
    "                        'return_rmse': return_metrics['rmse'],\n",
    "                        'hit_rate': return_metrics['hit_rate'],\n",
    "                        'volatility_ratio': return_metrics['volatility_ratio'],\n",
    "                        'price_mae': price_mae,\n",
    "                        'price_mape': price_mape,\n",
    "                        'predicted_returns': predictions,\n",
    "                        'actual_returns': actual_returns,\n",
    "                        'predicted_prices': predicted_prices,\n",
    "                        'actual_prices': actual_prices\n",
    "                    }\n",
    "                    \n",
    "                    results.append(result)\n",
    "                    \n",
    "                    print(f\"  ✓ Return MAE: {return_metrics['mae']:.6f}\")\n",
    "                    print(f\"  ✓ Hit Rate: {return_metrics['hit_rate']:.3f}\")\n",
    "                    print(f\"  ✓ Price MAE: ${price_mae:.2f}\")\n",
    "                    print(f\"  ✓ Price MAPE: {price_mape:.2f}%\")\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"  ⚠️  Insufficient test data for horizon {horizon}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  ❌ Error: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "print(f\"\\nCompleted {len(results)} forecasting experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Analysis and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame for analysis\n",
    "results_df = pd.DataFrame([\n",
    "    {k: v for k, v in result.items() if k not in ['predicted_returns', 'actual_returns', 'predicted_prices', 'actual_prices']}\n",
    "    for result in results\n",
    "])\n",
    "\n",
    "print(\"=== RESULTS SUMMARY ===\")\n",
    "print(results_df.groupby(['model', 'context_window', 'horizon']).agg({\n",
    "    'return_mae': 'mean',\n",
    "    'hit_rate': 'mean',\n",
    "    'price_mae': 'mean',\n",
    "    'price_mape': 'mean'\n",
    "}).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best configurations\n",
    "print(\"\\n=== BEST CONFIGURATIONS ===\")\n",
    "\n",
    "# Best by return MAE\n",
    "best_return_mae = results_df.loc[results_df['return_mae'].idxmin()]\n",
    "print(f\"Best Return MAE: {best_return_mae['return_mae']:.6f}\")\n",
    "print(f\"  Model: {best_return_mae['model']}\")\n",
    "print(f\"  Context: {best_return_mae['context_window']}\")\n",
    "print(f\"  Horizon: {best_return_mae['horizon']}\")\n",
    "print(f\"  Hit Rate: {best_return_mae['hit_rate']:.3f}\")\n",
    "\n",
    "# Best by hit rate\n",
    "best_hit_rate = results_df.loc[results_df['hit_rate'].idxmax()]\n",
    "print(f\"\\nBest Hit Rate: {best_hit_rate['hit_rate']:.3f}\")\n",
    "print(f\"  Model: {best_hit_rate['model']}\")\n",
    "print(f\"  Context: {best_hit_rate['context_window']}\")\n",
    "print(f\"  Horizon: {best_hit_rate['horizon']}\")\n",
    "print(f\"  Return MAE: {best_hit_rate['return_mae']:.6f}\")\n",
    "\n",
    "# Best by price MAE\n",
    "best_price_mae = results_df.loc[results_df['price_mae'].idxmin()]\n",
    "print(f\"\\nBest Price MAE: ${best_price_mae['price_mae']:.2f}\")\n",
    "print(f\"  Model: {best_price_mae['model']}\")\n",
    "print(f\"  Context: {best_price_mae['context_window']}\")\n",
    "print(f\"  Horizon: {best_price_mae['horizon']}\")\n",
    "print(f\"  Hit Rate: {best_price_mae['hit_rate']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Return MAE by model\n",
    "sns.boxplot(data=results_df, x='model', y='return_mae', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Return MAE by Model')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Hit Rate by model\n",
    "sns.boxplot(data=results_df, x='model', y='hit_rate', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Hit Rate by Model')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Price MAE by context window\n",
    "sns.boxplot(data=results_df, x='context_window', y='price_mae', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Price MAE by Context Window')\n",
    "\n",
    "# Price MAPE by horizon\n",
    "sns.boxplot(data=results_df, x='horizon', y='price_mape', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Price MAPE by Horizon')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detailed Analysis of Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the best configuration in detail\n",
    "best_idx = results_df['return_mae'].idxmin()\n",
    "best_result = results[best_idx]\n",
    "\n",
    "print(f\"=== DETAILED ANALYSIS OF BEST CONFIGURATION ===\")\n",
    "print(f\"Model: {best_result['model']}\")\n",
    "print(f\"Context Window: {best_result['context_window']} days\")\n",
    "print(f\"Prediction Horizon: {best_result['horizon']} days\")\n",
    "print(f\"\\nReturn Metrics:\")\n",
    "print(f\"  MAE: {best_result['return_mae']:.6f}\")\n",
    "print(f\"  RMSE: {best_result['return_rmse']:.6f}\")\n",
    "print(f\"  Hit Rate: {best_result['hit_rate']:.3f}\")\n",
    "print(f\"  Volatility Ratio: {best_result['volatility_ratio']:.3f}\")\n",
    "print(f\"\\nPrice Metrics:\")\n",
    "print(f\"  MAE: ${best_result['price_mae']:.2f}\")\n",
    "print(f\"  MAPE: {best_result['price_mape']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of best result\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Return comparison\n",
    "dates = test_returns.index[:len(best_result['actual_returns'])]\n",
    "axes[0, 0].plot(dates, best_result['actual_returns'], 'b-', label='Actual Returns', linewidth=2)\n",
    "axes[0, 0].plot(dates, best_result['predicted_returns'], 'r--', label='Predicted Returns', linewidth=2)\n",
    "axes[0, 0].set_title('Return Comparison')\n",
    "axes[0, 0].set_ylabel('Log Return')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Price comparison\n",
    "axes[0, 1].plot(dates, best_result['actual_prices'], 'b-', label='Actual Prices', linewidth=2)\n",
    "axes[0, 1].plot(dates, best_result['predicted_prices'], 'r--', label='Predicted Prices', linewidth=2)\n",
    "axes[0, 1].set_title('Price Comparison')\n",
    "axes[0, 1].set_ylabel('Price ($)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Return scatter plot\n",
    "axes[1, 0].scatter(best_result['actual_returns'], best_result['predicted_returns'], alpha=0.7)\n",
    "axes[1, 0].plot([-0.1, 0.1], [-0.1, 0.1], 'r--', alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Actual Returns')\n",
    "axes[1, 0].set_ylabel('Predicted Returns')\n",
    "axes[1, 0].set_title('Return Scatter Plot')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Error analysis\n",
    "return_errors = best_result['actual_returns'] - best_result['predicted_returns']\n",
    "axes[1, 1].hist(return_errors, bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Return Prediction Error')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Error Distribution')\n",
    "axes[1, 1].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Error statistics\n",
    "print(f\"\\n=== ERROR ANALYSIS ===\")\n",
    "print(f\"Return Error Mean: {return_errors.mean():.6f}\")\n",
    "print(f\"Return Error Std: {return_errors.std():.6f}\")\n",
    "print(f\"Return Error Skewness: {stats.skew(return_errors):.4f}\")\n",
    "print(f\"Return Error Kurtosis: {stats.kurtosis(return_errors):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison with Absolute Price Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from absolute price approach for comparison\n",
    "price_results_path = '../gold_futures_analysis/phase1_final_comparison_results.csv'\n",
    "\n",
    "try:\n",
    "    price_results = pd.read_csv(price_results_path)\n",
    "    \n",
    "    # Find best price-based result\n",
    "    best_price_result = price_results.loc[price_results['mae'].idxmin()]\n",
    "    \n",
    "    print(\"=== COMPARISON: LOG RETURNS vs ABSOLUTE PRICES ===\")\n",
    "    print(f\"\\nBest Log Returns Approach:\")\n",
    "    print(f\"  Model: {best_result['model']}\")\n",
    "    print(f\"  Context: {best_result['context_window']} days\")\n",
    "    print(f\"  Horizon: {best_result['horizon']} days\")\n",
    "    print(f\"  Price MAE: ${best_result['price_mae']:.2f}\")\n",
    "    print(f\"  Price MAPE: {best_result['price_mape']:.2f}%\")\n",
    "    print(f\"  Hit Rate: {best_result['hit_rate']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nBest Absolute Price Approach:\")\n",
    "    print(f\"  Model: {best_price_result['model']}\")\n",
    "    print(f\"  Context: {best_price_result['context_window']} days\")\n",
    "    print(f\"  Horizon: {best_price_result['horizon']} days\")\n",
    "    print(f\"  Price MAE: ${best_price_result['mae']:.2f}\")\n",
    "    print(f\"  Price MAPE: {best_price_result['mape']:.2f}%\")\n",
    "    print(f\"  Hit Rate: {best_price_result['directional_accuracy']:.3f}\")\n",
    "    \n",
    "    # Calculate improvement\n",
    "    mae_improvement = (best_price_result['mae'] - best_result['price_mae']) / best_price_result['mae'] * 100\n",
    "    mape_improvement = (best_price_result['mape'] - best_result['price_mape']) / best_price_result['mape'] * 100\n",
    "    hit_rate_improvement = (best_result['hit_rate'] - best_price_result['directional_accuracy']) / best_price_result['directional_accuracy'] * 100\n",
    "    \n",
    "    print(f\"\\n=== IMPROVEMENT ANALYSIS ===\")\n",
    "    print(f\"MAE Improvement: {mae_improvement:+.2f}%\")\n",
    "    print(f\"MAPE Improvement: {mape_improvement:+.2f}%\")\n",
    "    print(f\"Hit Rate Improvement: {hit_rate_improvement:+.2f}%\")\n",
    "    \n",
    "    if mae_improvement > 0:\n",
    "        print(f\"\\n✅ Log returns approach shows {mae_improvement:.1f}% better MAE performance\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Log returns approach shows {abs(mae_improvement):.1f}% worse MAE performance\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Price-based results not found. Run the absolute price analysis first for comparison.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading price results: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df.to_csv('./results/log_returns_analysis_results.csv', index=False)\n",
    "\n",
    "# Save detailed best result\n",
    "best_result_detailed = {\n",
    "    'configuration': {\n",
    "        'model': best_result['model'],\n",
    "        'context_window': best_result['context_window'],\n",
    "        'horizon': best_result['horizon']\n",
    "    },\n",
    "    'return_metrics': {\n",
    "        'mae': best_result['return_mae'],\n",
    "        'rmse': best_result['return_rmse'],\n",
    "        'hit_rate': best_result['hit_rate'],\n",
    "        'volatility_ratio': best_result['volatility_ratio']\n",
    "    },\n",
    "    'price_metrics': {\n",
    "        'mae': best_result['price_mae'],\n",
    "        'mape': best_result['price_mape']\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('./results/best_log_returns_config.json', 'w') as f:\n",
    "    json.dump(best_result_detailed, f, indent=2)\n",
    "\n",
    "print(\"✅ Results saved successfully!\")\n",
    "print(f\"  - Summary: ./results/log_returns_analysis_results.csv\")\n",
    "print(f\"  - Best config: ./results/best_log_returns_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Findings and Recommendations\n",
    "\n",
    "### Statistical Properties\n",
    "- **Stationarity**: Log returns show [stationarity status] vs prices\n",
    "- **Distribution**: Returns are [more/less] normally distributed than price changes\n",
    "- **Volatility**: Returns provide direct volatility modeling capability\n",
    "\n",
    "### Model Performance\n",
    "- **Best Configuration**: [model] with [context] context and [horizon] horizon\n",
    "- **Return Accuracy**: MAE of [value] with [hit_rate] directional accuracy\n",
    "- **Price Reconstruction**: MAE of $[value] with [mape]% MAPE\n",
    "\n",
    "### Comparison with Absolute Price Approach\n",
    "- **Improvement**: [+/-X%] in MAE, [+/-X%] in MAPE\n",
    "- **Directional Accuracy**: [+/-X%] improvement in hit rate\n",
    "- **Model Efficiency**: Returns approach shows [better/worse] generalization\n",
    "\n",
    "### Recommendations\n",
    "1. **Production Use**: [Recommend/Don't recommend] log returns for gold futures\n",
    "2. **Optimal Settings**: Use [best_config] for live trading\n",
    "3. **Risk Management**: Returns provide direct volatility estimates\n",
    "4. **Ensemble Approach**: Consider combining with absolute price models\n",
    "\n",
    "### Next Steps\n",
    "1. **Extended Testing**: Validate on 2022-2024 data\n",
    "2. **Volatility Modeling**: Implement GARCH-style conditional volatility\n",
    "3. **Multi-horizon**: Develop path-dependent return forecasting\n",
    "4. **Feature Engineering**: Add technical indicators to return series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
